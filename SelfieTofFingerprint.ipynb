{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selfies as sf\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit import RDLogger\n",
    "from rdkit.DataStructs.cDataStructs import TanimotoSimilarity\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import myModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"moses_train.csv\")\n",
    "test_data = pd.read_csv(\"moses_test.csv\")\n",
    "\n",
    "raw_data = pd.concat([train_data, test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fingerprint_from_smile(smile=str()):\n",
    "  mol = Chem.MolFromSmiles(smile)\n",
    "  fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=2048) #could 2048 bits be a hyperparams\n",
    "  return fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selfies_alphabet(selfies_list=list()):\n",
    "\n",
    "    #  Define selfies Alphabet with padding symbol included \n",
    "    all_selfies_symbols = sf.get_alphabet_from_selfies(selfies_list)\n",
    "    all_selfies_symbols.add('[nop]') # [nop] is the canonical padding symbol supported by the selfies library \n",
    "    selfies_alphabet = list(sorted(all_selfies_symbols))\n",
    "\n",
    "    return selfies_alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanimotoLoss(outputs, labels):\n",
    "\n",
    "    zipped = list(zip(outputs, labels))\n",
    "    \n",
    "    total_loss = 0\n",
    "    for output, label in zipped:\n",
    "        #specifying the batch size\n",
    "        #output = output > 0.5\n",
    "        \n",
    "        N_AB = torch.dot(output, label)\n",
    "        N_A = torch.sum(output)\n",
    "        N_B = torch.sum(label)\n",
    "        coeff = N_AB / (N_A + N_B - N_AB)\n",
    "        loss = 1-coeff\n",
    "        total_loss += loss\n",
    "    \n",
    "    return total_loss/len(zipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max(sf.len_selfies(s) for s in raw_data[\"selfies\"])\n",
    "\n",
    "alphabet = selfies_alphabet(raw_data[\"selfies\"])\n",
    "\n",
    "vocab_stoi = {symbol: idx for idx, symbol in enumerate(alphabet)}\n",
    "\n",
    "vocab_itos = {idx: symbol for symbol, idx in vocab_stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_len = len(vocab_stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "selfies = list(raw_data[\"selfies\"])\n",
    "smiles = list(raw_data[\"smiles\"])\n",
    "\n",
    "selfies_train, selfies_test, smiles_train, smiles_test = train_test_split(selfies, smiles, test_size=0.33, random_state=42)\n",
    "selfies_train, selfies_val, smiles_train, smiles_val = train_test_split(selfies_train, smiles_train, test_size=0.20, random_state=42)\n",
    "\n",
    "train_data = list(zip(selfies_train, smiles_train))\n",
    "val_data = list(zip(selfies_val, smiles_val))\n",
    "test_data = list(zip(selfies_test, smiles_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from rdkit.Chem import DataStructs\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=1000, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=1000, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=1000, shuffle=True)\n",
    "\n",
    "net = myModel.Net(max_len*alpha_len, 1600, 1800, 2048)\n",
    "\n",
    "#hyperparam\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "def train_one_epoch(epoch_index):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    for i, sample in enumerate(train_loader):\n",
    "        selfies, smiles = sample\n",
    "        \n",
    "        inputs = sf.batch_selfies_to_flat_hot(selfies, vocab_stoi, pad_to_len=max_len)\n",
    "        inputs = torch.tensor(inputs).float()\n",
    "        \n",
    "        labels = []\n",
    "        for smile in smiles:\n",
    "            fp = fingerprint_from_smile(smile)\n",
    "            fp = fingerprint_from_smile(smile)\n",
    "            fp_arr = np.zeros((0,), dtype=np.float32)\n",
    "            DataStructs.ConvertToNumpyArray(fp,fp_arr)\n",
    "            labels.append(fp_arr)\n",
    "        labels = torch.tensor(labels)\n",
    "        \n",
    "        optimizer.zero_grad()       \n",
    "        outputs = net(inputs)\n",
    "        #loss = tanimotoLoss(outputs, labels)\n",
    "        #loss = Variable(loss, requires_grad = True)\n",
    "        otherloss = nn.BCELoss()\n",
    "        loss = otherloss(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        #reporting performance\n",
    "        print(loss.item())\n",
    "        running_loss += loss.item()\n",
    "        if i % 500 == 499:\n",
    "            last_loss = running_loss / 500 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            running_loss = 0.0\n",
    "    return last_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "0.7286798357963562\n",
      "0.32938316464424133\n",
      "0.0980440154671669\n",
      "0.20179259777069092\n",
      "0.12327368557453156\n",
      "0.0802442654967308\n",
      "0.0921555608510971\n",
      "0.10937304049730301\n",
      "0.1180245578289032\n",
      "0.11828535795211792\n",
      "0.109224334359169\n",
      "0.09933117032051086\n",
      "0.09044301509857178\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/zoewefers/Desktop/Waldispuhl Lab/SELFIES Data/SelfieTofFingerprint.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/zoewefers/Desktop/Waldispuhl%20Lab/SELFIES%20Data/SelfieTofFingerprint.ipynb#ch0000020?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEPOCH \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(epoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/zoewefers/Desktop/Waldispuhl%20Lab/SELFIES%20Data/SelfieTofFingerprint.ipynb#ch0000020?line=7'>8</a>\u001b[0m net\u001b[39m.\u001b[39mtrain(\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/zoewefers/Desktop/Waldispuhl%20Lab/SELFIES%20Data/SelfieTofFingerprint.ipynb#ch0000020?line=8'>9</a>\u001b[0m avg_loss \u001b[39m=\u001b[39m train_one_epoch(epoch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zoewefers/Desktop/Waldispuhl%20Lab/SELFIES%20Data/SelfieTofFingerprint.ipynb#ch0000020?line=10'>11</a>\u001b[0m net\u001b[39m.\u001b[39mtrain(\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zoewefers/Desktop/Waldispuhl%20Lab/SELFIES%20Data/SelfieTofFingerprint.ipynb#ch0000020?line=12'>13</a>\u001b[0m running_vloss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n",
      "\u001b[1;32m/Users/zoewefers/Desktop/Waldispuhl Lab/SELFIES Data/SelfieTofFingerprint.ipynb Cell 11'\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(epoch_index)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zoewefers/Desktop/Waldispuhl%20Lab/SELFIES%20Data/SelfieTofFingerprint.ipynb#ch0000018?line=12'>13</a>\u001b[0m labels \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zoewefers/Desktop/Waldispuhl%20Lab/SELFIES%20Data/SelfieTofFingerprint.ipynb#ch0000018?line=13'>14</a>\u001b[0m \u001b[39mfor\u001b[39;00m smile \u001b[39min\u001b[39;00m smiles:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/zoewefers/Desktop/Waldispuhl%20Lab/SELFIES%20Data/SelfieTofFingerprint.ipynb#ch0000018?line=14'>15</a>\u001b[0m     fp \u001b[39m=\u001b[39m fingerprint_from_smile(smile)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zoewefers/Desktop/Waldispuhl%20Lab/SELFIES%20Data/SelfieTofFingerprint.ipynb#ch0000018?line=15'>16</a>\u001b[0m     fp \u001b[39m=\u001b[39m fingerprint_from_smile(smile)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zoewefers/Desktop/Waldispuhl%20Lab/SELFIES%20Data/SelfieTofFingerprint.ipynb#ch0000018?line=16'>17</a>\u001b[0m     fp_arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39m0\u001b[39m,), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)\n",
      "\u001b[1;32m/Users/zoewefers/Desktop/Waldispuhl Lab/SELFIES Data/SelfieTofFingerprint.ipynb Cell 4'\u001b[0m in \u001b[0;36mfingerprint_from_smile\u001b[0;34m(smile)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/zoewefers/Desktop/Waldispuhl%20Lab/SELFIES%20Data/SelfieTofFingerprint.ipynb#ch0000002?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfingerprint_from_smile\u001b[39m(smile\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m()):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/zoewefers/Desktop/Waldispuhl%20Lab/SELFIES%20Data/SelfieTofFingerprint.ipynb#ch0000002?line=1'>2</a>\u001b[0m   mol \u001b[39m=\u001b[39m Chem\u001b[39m.\u001b[39;49mMolFromSmiles(smile)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/zoewefers/Desktop/Waldispuhl%20Lab/SELFIES%20Data/SelfieTofFingerprint.ipynb#ch0000002?line=2'>3</a>\u001b[0m   fp \u001b[39m=\u001b[39m AllChem\u001b[39m.\u001b[39mGetMorganFingerprintAsBitVect(mol, \u001b[39m2\u001b[39m, nBits\u001b[39m=\u001b[39m\u001b[39m2048\u001b[39m) \u001b[39m#could 2048 bits be a hyperparams\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/zoewefers/Desktop/Waldispuhl%20Lab/SELFIES%20Data/SelfieTofFingerprint.ipynb#ch0000002?line=3'>4</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fp\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "NUM_EPOCHS = 5\n",
    "best_vloss = 1,000,000.\n",
    "\n",
    "epoch_number = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch + 1))\n",
    "    net.train(True)\n",
    "    avg_loss = train_one_epoch(epoch)\n",
    "\n",
    "    net.train(False)\n",
    "    \n",
    "    running_vloss = 0.0\n",
    "    for i, sample in enumerate(val_loader):\n",
    "        seflies, smiles = sample\n",
    "\n",
    "        inputs = sf.batch_selfies_to_flat_hot(selfies, vocab_stoi, pad_to_len=max_len)\n",
    "        inputs = torch.tensor(inputs).float()\n",
    "        \n",
    "        labels = []\n",
    "        for smile in smiles:\n",
    "            fp = fingerprint_from_smile(smile)\n",
    "            fp = fingerprint_from_smile(smile)\n",
    "            fp_arr = np.zeros((0,), dtype=np.float32)\n",
    "            DataStructs.ConvertToNumpyArray(fp,fp_arr)\n",
    "            labels.append(fp_arr)\n",
    "        labels = torch.tensor(labels)\n",
    "\n",
    "        pred_outputs = net(inputs)\n",
    "        tuples = list(zip(pred_outputs, labels))\n",
    "        losses = tanimotoLoss(pred_outputs, labels)\n",
    "        running_vloss +=losses"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "390fbcb932543dc56d0a09bd8f8ddfc06ed8c4af07a071e430c5e89a6d9ad5ed"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
